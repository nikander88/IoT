{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# BL40A2010 Introduction to IoT-Based Systems\n",
    "\n",
    "## Assignment 6, 22.10.2020\n",
    "\n",
    "### Author: Niki Malmsten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prisoner's dilemma** is a standard example of a game analyzed in game theory that shows why two completely rational individuals might not cooperate, even if it appears that it is in their best interests to do so. It was originally framed by Merrill Flood and Melvin Dresher while working at RAND in 1950. Albert W. Tucker formalized the game with prison sentence rewards and named it \"prisoner's dilemma\", presenting it as follows:\n",
    "\n",
    "\"Two members of a criminal gang are arrested and imprisoned. Each prisoner is in solitary confinement with no means of communicating with the other. The prosecutors lack sufficient evidence to convict the pair on the principal charge, but they have enough to convict both on a lesser charge. Simultaneously, the prosecutors offer each prisoner a bargain. Each prisoner is given the opportunity either to betray the other by testifying that the other committed the crime, or to cooperate with the other by remaining silent. The possible outcomes are:\n",
    "\n",
    "- If A and B each betray the other (not-cooperating to each other), each of them serves $z$ years in prison (payoff of $-z$)\n",
    "- If A betrays B (not-cooperating with B) but B remains silent (cooperating with A), A will serve $y$ years in prison (payoff $-y$) and B will serve $w$ years  (payoff of $-w$).\n",
    "- If B betrays A (not-cooperating with A) but A remains silent (cooperating with B), B will serve $y$ years in prison (payoff $-y$) and A will serve $w$ years  (payoff of $-w$).\n",
    "- If A and B both remain silent, both of them will serve $x$ years in prison (payoff of $-x$).\"\n",
    "\n",
    "The payoff table is presented below. \n",
    "\n",
    "|                | $B$ cooperates  | $B$ not-cooperating   |\n",
    "|----------------|:---------------:|--------------:|\n",
    "| $A$ cooperates |  $A \\rightarrow -x$   | $A\\rightarrow -w$  |\n",
    "|                |  $B\\rightarrow -x$   | $B\\rightarrow -y$  |\n",
    "|                |                 |               |\n",
    "| $A$ not-cooperating   |  $A\\rightarrow -y$   | $A\\rightarrow -z$  |\n",
    "|                |  $B\\rightarrow -w$   | $B\\rightarrow -z$  |\n",
    "\n",
    "**However, this is only a *Prisoner's Dilemma GAME* for A GIVEN RELATION between the years in prison (payoffs) as to be studied next.**\n",
    "\n",
    "ps. Text adapted from [Wikipedia](https://en.wikipedia.org/wiki/Prisoner's_dilemma)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(1) Consider the Prisoner's dilemma description given above.**\n",
    "\n",
    "**(a) What is the relation between the payoffs values $x\\geq 0$, $y\\geq 0$, $w\\geq 0$ and $z \\geq 0$ so that the game can be classified as [Prisoner's Dilemma](https://en.wikipedia.org/wiki/Prisoner's_dilemma)?**\n",
    "\n",
    "**(b) Verify the results (i.e., the proposed inequality) with numerical examples using [nashpy](https://nashpy.readthedocs.io/en/stable/index.html). Please provide one example when the inequality holds and one it does not (check my example for Dove and Hawyk game).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nashpy\n",
      "  Downloading nashpy-0.0.19.tar.gz (8.3 kB)\n",
      "Collecting numpy>=1.12.1\n",
      "  Downloading numpy-1.19.2-cp37-cp37m-manylinux2010_x86_64.whl (14.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 14.5 MB 4.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting scipy>=0.19.0\n",
      "  Downloading scipy-1.5.3-cp37-cp37m-manylinux1_x86_64.whl (25.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 25.9 MB 39.4 MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: nashpy\n",
      "  Building wheel for nashpy (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for nashpy: filename=nashpy-0.0.19-py3-none-any.whl size=10814 sha256=96513763045143dcdb504263bb363f8afff5184a038911c3634c6ead45204752\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/8e/b8/e4/255ea14bf12a196a4d0e934124c2dfc26d6e4d1111e5c271d3\n",
      "Successfully built nashpy\n",
      "Installing collected packages: numpy, scipy, nashpy\n",
      "Successfully installed nashpy-0.0.19 numpy-1.19.2 scipy-1.5.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nashpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nashpy as nash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-3-971e14f770e6>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-3-971e14f770e6>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    a.) cooperation is better than not cooperating, so x > z\u001b[0m\n\u001b[0m      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "a.) cooperation is better than not cooperating, so x > z\n",
    "if only other does not cooperate, it results to a reward, so y > w\n",
    "when out together x > y > z > w\n",
    "x = 1\n",
    "z = 3\n",
    "y = 2\n",
    "w = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bi matrix game with payoff matrices:\n",
       "\n",
       "Row player:\n",
       "[[1 5]\n",
       " [2 3]]\n",
       "\n",
       "Column player:\n",
       "[[1 2]\n",
       " [5 3]]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with these values the result will be inequal, so it's logical to not cooperate, but\n",
    "# the best solution is still to cooperate. This would make the game prisoners dilemma\n",
    "A = [[1, 5], [2, 3]]\n",
    "B = [[1, 2], [5, 3]]\n",
    "prisoner = nash.Game(A, B)\n",
    "prisoner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([1., 0.]), array([0., 1.])),\n",
       " (array([0., 1.]), array([1., 0.])),\n",
       " (array([0.66666667, 0.33333333]), array([0.66666667, 0.33333333]))]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eqs = prisoner.support_enumeration()\n",
    "list(eqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bi matrix game with payoff matrices:\n",
       "\n",
       "Row player:\n",
       "[[1 4]\n",
       " [2 3]]\n",
       "\n",
       "Column player:\n",
       "[[1 2]\n",
       " [4 3]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with these values the result will be equal, there isn't a big reward to not cooperate\n",
    "# or to cooperate, but ther best solution still remains for both to cooperate. This is\n",
    "# still prisoners dilemma game\n",
    "A = [[1, 4], [2, 3]]\n",
    "B = [[1, 2], [4, 3]]\n",
    "prisoner = nash.Game(A, B)\n",
    "prisoner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([1., 0.]), array([0., 1.])),\n",
       " (array([0., 1.]), array([1., 0.])),\n",
       " (array([0.5, 0.5]), array([0.5, 0.5]))]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eqs = prisoner.support_enumeration()\n",
    "list(eqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bi matrix game with payoff matrices:\n",
       "\n",
       "Row player:\n",
       "[[2 4]\n",
       " [1 3]]\n",
       "\n",
       "Column player:\n",
       "[[2 1]\n",
       " [4 3]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with these values the game will change and logical result is not to cooperate.\n",
    "# this is not a prisoners dilemma game\n",
    "A = [[2, 4], [1, 3]]\n",
    "B = [[2, 1], [4, 3]]\n",
    "prisoner = nash.Game(A, B)\n",
    "prisoner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([1., 0.]), array([1., 0.]))]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eqs = prisoner.support_enumeration()\n",
    "list(eqs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(2) Justify why the game from the previous exercise is or is not a good (reasonable) model when $A$ and $B$ are:**\n",
    "\n",
    "**1. Two trained members from the army when they are in prison.**\n",
    "I assume that people who have army training will be silent, meaning they will cooperate, which would make the game not a good model because they would always cooperate. But if them being soldiers doesen't matter it would be a good model, because being scared that the other one would not cooperate could cause the other to not cooperate either.\n",
    "\n",
    "**2. Competitive companies in the market discussing standardization.**\n",
    "I think it's almost a good model, when the companies cooperate, they both gain from it and can strategize, but if the other doesen't cooperate it wins the competion and could gain everything and if both don't cooperate it's the 3rd worst solution. So if only the other does not cooperate it wins more then if they both cooperate.\n",
    "\n",
    "**3. Two different autonomous IoT-based home energy management algorithms that are focus on energy efficiency.**\n",
    "The goal is energy efficiency, so there is no reason to not work together, they both get the best outcome whne they work together.\n",
    "\n",
    "**4. Two different autonomous IoT-based home energy management algorithms that are focus on profit maximization.**\n",
    "I think the prisoners dilemma is an ok model, because if they cooperate they both win by making a better service that could cost more, if only other cooperates the other gets a better service meaning more money so the other one doesen't get that much, if neither cooperate they can't charge that much for the service. But in the ned I don't see huge reasons for cooperation, because it propably wouldn't generate much more money.\n",
    "\n",
    "\n",
    "**ps. You need to think about the assumption used in Game Theory and in the Prisoner's dilemma problem setting.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
